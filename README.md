## Hi there 👋

## 🔍 About Me
I'm a tech enthusiast with a passion for machine learning, data science, and database systems. I enjoy working on data-driven projects that uncover insights and drive decision-making.
Currently, I'm expanding my skills in advanced machine learning models and deep learning, with a growing interest in real-world applications across healthcare, finance, and more.
I enjoy building clean, interpretable models, exploring data pipelines, and understanding how different technologies work together to solve complex problems.
Outside of coding, I'm always curious—whether it’s reading up on new AI research or experimenting with datasets to sharpen my skills.

## 📊 Skills
- Languages: Python, SQL, R, HTML, C++, C
- Databases: MySQL,Postgres
- Analytics, ML and EDA: Statistical Modelling, Sckit-learn, Pandas, Matplotlib, Seaborn and Tidyverse
- Tools: Git

## 🧠 Projects
- **Machine Learning - Diabetes Prediction** – This project aimed to predict Type 2 diabetes in Pima Indian women using a dataset of 768 patients and eight clinical variables. After handling missing values and scaling features, multiple models were tested, including Logistic Regression and Support Vector Machines. A calibrated Random Forest classifier was ultimately selected for its strong performance, achieving a recall of 0.889—critical for minimizing missed diagnoses—along with a robust ROC-AUC score of 0.832. Key features like glucose, BMI, and age aligned with known diabetes risk factors, reinforcing the model’s clinical relevance.
 
- **Advanced Statistics - Classification & Clustering Analysis** – This project explored a multi-class classification problem using a 3,000-sample dataset with 20 continuous features. After thorough data cleaning (imputation, outlier removal, correlation checks), a multinomial logistic regression model achieved 85% accuracy. Principal Component Analysis (PCA) was applied to reduce dimensionality and visualize feature variance, while K-Means clustering (k=3) uncovered natural groupings aligned with PCA results. The analysis demonstrated how combining supervised and unsupervised learning can improve interpretability and reveal deeper structure in complex datasets.

- **Database Systems** – This project explored the design and implementation of both relational and NoSQL databases using a real-world air pollution dataset. A normalized ER model was created and forward-engineered into MySQL, followed by data cleaning and importing using Python and phpMyAdmin. SQL queries were written to analyze pollution levels, while XML and BaseX were used to model and query hierarchical data. The project highlighted the strengths of relational databases for data integrity and NoSQL for flexible, semi-structured data, offering hands-on experience in both paradigms.

## 📫 Let's Connect
- [LinkedIn](https://www.linkedin.com/in/doreen-mwangi/)

## 🔭 Currently working on;
I’m currently conducting an independent machine learning research project as part of a 10,000-word dissertation, to be completed in summer 2025. The project focuses on predicting the impact of climate change on the GDP of various countries by collecting and preprocessing global climate and economic data, training predictive models, and analyzing relationships between environmental and economic variables. This work builds on concepts from my Advanced Statistics and Machine Learning modules, where I’ve applied multivariate analysis, regression techniques, and supervised learning methods to explore complex, real-world data challenges.

## 🌱 Currently Leaning;
I’m currently learning and deepening my expertise in data science through advanced academic modules that cover both technical and applied aspects of the field:

Advanced Statistics – Enhancing my skills in multivariate analysis, regression modeling, and interpreting complex datasets to support data-driven decisions.

Programming for Data Science – Building strong proficiency in Python for data manipulation, automation, and analytical problem-solving.

Data Management Fundamentals – Working with SQL and NoSQL databases to manage structured and semi-structured data, alongside techniques for cleaning, transforming, and modeling datasets.

Interdisciplinary Group Project – Collaborating in a cross-functional team on a real-world data challenge, applying the full data science lifecycle from problem framing to insight delivery.

Statistical Inference – Gaining practical knowledge in hypothesis testing, confidence intervals, and Bayesian methods for sound statistical analysis.

Machine Learning – Applying supervised and unsupervised algorithms like decision trees, clustering, and ensemble models, with a focus on model development, evaluation, and deployment.

## ⚡ Fun fact: 
I enjoy playing chess in my free time. It sharpens my strategic thinking, improves pattern recognition, and helps me stay focused under pressure, skills that I find incredibly useful in both coding and data analysis.
